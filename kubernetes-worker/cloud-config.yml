#cloud-config
coreos:
  update:
    reboot-strategy: ${reboot_strategy}
  etcd2:
    discovery-srv: ${domain}
    proxy: on
  flannel:
    interface: $private_ipv4
    etcd_endpoints: http://127.0.0.1:2379
  units:
    - name: etcd2.service
      command: start
    - name: flanneld.service
      command: start
    - name: docker.service
      drop-ins:
      - name: "40-flannel.conf"
        content: |
          [Unit]
          Requires=flanneld.service
          After=flanneld.service
    - name: kube-proxy.service
      command: start
      content: |
        [Unit]
        Description="Kubernetes Proxy"
        Requires=flanneld.service
        After=flanneld.service
        [Service]
        Restart=always
        TimeoutStartSec=300
        ExecStartPre=/bin/docker pull quay.io/coreos/hyperkube:v1.2.0_coreos.0
        ExecStart=/bin/docker run --rm --name kube-proxy --privileged --net host \
        -v /usr/share/ca-certificates:/etc/ssl/certs:ro \
        -v /etc/kubernetes/worker-kubeconfig.yaml:/etc/kubernetes/worker-kubeconfig.yaml:ro \
        -v /etc/kubernetes/ssl:/etc/kubernetes/ssl:ro \
        quay.io/coreos/hyperkube:v1.2.0_coreos.0 \
        /hyperkube \
        proxy \
        --master=https://master-internal.${domain} \
        --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
        --proxy-mode=iptables
        ExecStop=/bin/docker stop -t 2 kube-proxy
    - name: kubelet.service
      command: start
      content: |
        [Unit]
        Description="Kubelet Service"
        Requires=flanneld.service
        After=kubernetes-certs.service
        After=flanneld.service
        [Service]
        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
        Restart=always
        Environment=KUBELET_VERSION=v1.2.0_coreos.0
        ExecStart=/usr/lib/coreos/kubelet-wrapper \
        --api-servers=https://master-internal.${domain} \
        --register-node=true \
        --allow-privileged=true \
        --config=/etc/kubernetes/manifests \
        --hostname-override=${name} \
        --cluster-domain=cluster.local \
        --cluster-dns=172.17.0.10 \
        --tls-cert-file=/etc/kubernetes/ssl/${name}.pem \
        --tls-private-key-file=/etc/kubernetes/ssl/${name}-key.pem \
        --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
        --node-ip=$private_ipv4
        Restart=always
        RestartSec=10
        [Install]
        WantedBy=multi-user.target
    - name: kubernetes-certs.service
      command: start
      content: |
        [Unit]
        Description="creates required kubernetes worker certs"
        Before=kube-proxy.service
        [Service]
        ExecStart=/etc/kubernetes/ssl/create_certs.sh
        RemainAfterExit=yes
        Type=oneshot
    - name: sshd.socket
      command: restart
      content: |
        [Socket]
        ListenStream=2042
        Accept=yes
    - name: settimezone.service
      command: start
      content: |
        [Unit]
        Description=Set the timezone
        [Service]
        ExecStart=/usr/bin/timedatectl set-timezone UTC
        RemainAfterExit=yes
        Type=oneshot
write_files:
  - path: /etc/kubernetes/worker-kubeconfig.yaml
    content: |
      apiVersion: v1
      kind: Config
      clusters:
        - name: local
          cluster:
            certificate-authority: /etc/kubernetes/ssl/ca.pem
      users:
        - name: kubelet
          user:
            client-certificate: /etc/kubernetes/ssl/${name}.pem
            client-key: /etc/kubernetes/ssl/${name}-key.pem
      contexts:
        - context:
            cluster: local
            user: kubelet
          name: kubelet-context
      current-context: kubelet-context
  - path: /etc/ntp.conf
    content: |
      # Common pool
      server 0.pool.ntp.org
      server 1.pool.ntp.org

      # - Allow only time queries, at a limited rate.
      # - Allow all local queries (IPv4, IPv6)
      restrict default nomodify nopeer noquery limited kod
      restrict 127.0.0.1
      restrict [::1]
  - path: /etc/ssh/sshd_config
    permissions: 0600
    owner: root:root
    content: |
      # Use most defaults for sshd configuration.
      UsePrivilegeSeparation sandbox
      Subsystem sftp internal-sftp

      PermitRootLogin no
      AllowUsers core
      PasswordAuthentication no
      ChallengeResponseAuthentication no
  - path: /etc/kubernetes/ssl/ca.pem
    permissions: 644
    encoding: base64
    content: ${ca}
  - path: /etc/kubernetes/ssl/ca-key.pem
    permissions: 644
    encoding: base64
    content: ${ca_key}
  - path: /etc/kubernetes/ssl/worker-openssl.cnf
    content: |
      [req]
      req_extensions = v3_req
      distinguished_name = req_distinguished_name
      [req_distinguished_name]
      [ v3_req ]
      basicConstraints = CA:FALSE
      keyUsage = nonRepudiation, digitalSignature, keyEncipherment
      subjectAltName = @alt_names
      [alt_names]
      IP.1 = $public_ipv4
      IP.2 = $private_ipv4
  - path: /etc/kubernetes/ssl/create_certs.sh
    permissions: "755"
    content: |
      #!/bin/bash
      cd /etc/kubernetes/ssl
      openssl genrsa -out ${name}-key.pem 2048
      openssl req -new -key ${name}-key.pem -out ${name}.csr -subj "/CN=${name}" -config worker-openssl.cnf
      openssl x509 -req -in ${name}.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out ${name}.pem -days 365 -extensions v3_req -extfile worker-openssl.cnf
      sudo chmod 600 *-key.pem
      sudo chown root:root *-key.pem
      echo -n "$(cat ca.pem)" | sudo tee -a ${name}.pem